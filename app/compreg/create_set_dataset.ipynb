{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/project/remote/golmi-dynamatt',\n",
       " '/project/remote/golmi-dynamatt/app/compreg',\n",
       " '/usr/lib/python38.zip',\n",
       " '/usr/lib/python3.8',\n",
       " '/usr/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.8/dist-packages',\n",
       " '/usr/lib/python3/dist-packages']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/project/remote/golmi-dynamatt\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.pentomino import PieceConfig, RelPositions, Shapes, Colors, Board\n",
    "\n",
    "def draw_piece_image(color, shape):\n",
    "    target = PieceConfig(color, shape, RelPositions.CENTER)\n",
    "    board = Board(15, 15)  # we need at least size of 3 * 5\n",
    "    board.add_piece_from_config(target)\n",
    "    arr = board.to_rgb_array()\n",
    "    center = arr[5:10, 5:10]\n",
    "    return center\n",
    "\n",
    "def to_piece_image_name(color, shape):\n",
    "    return f\"{shape.value_name}_{color.value_name}.png\"\n",
    "\n",
    "def save_piece_image(color, shape, target_dir):\n",
    "    filename = to_piece_image_name(color, shape)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(draw_piece_image(color, shape))\n",
    "    plt.savefig(target_dir + f\"/{filename}\", bbox_inches='tight')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: 12 Colors: 8 Combinations: 96\n"
     ]
    }
   ],
   "source": [
    "shapes = list(Shapes)\n",
    "colors = list(Colors)\n",
    "num_colors = len(colors)\n",
    "num_shapes = len(shapes)\n",
    "num_target_looks = num_shapes * num_colors\n",
    "print(f\"Shapes: {num_shapes} Colors: {num_colors} Combinations: {num_target_looks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible sets: 884736\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Actually more sensible to store all possible combinations of pieces only once!\n",
    "# And then load them dynamically\n",
    "num_distractors = 2\n",
    "num_pieces = num_distractors + 1\n",
    "print(f\"Possible sets: {(num_target_looks)**(num_pieces)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other looks: 84\n",
      "Share looks: 7\n",
      "Possible comp. sets: 56448\n",
      "Possible val/test comp. sets: 7056\n",
      "Possible single comp. sets with 2 distractors: 588\n"
     ]
    }
   ],
   "source": [
    "# Compositional set on \"Colors\"\n",
    "# All other distractors do NOT share the color, but at least one distractor shares the shape\n",
    "num_other_looks = num_shapes*(num_colors-1) # unshare the color, but allow all shapes\n",
    "num_share_looks = num_colors-1              # unshare the color, but shares the same shape as the target piece\n",
    "print(f\"Other looks: {num_other_looks}\")\n",
    "print(f\"Share looks: {num_share_looks}\")\n",
    "\n",
    "print(f\"Possible comp. sets: {num_target_looks * num_share_looks * num_other_looks**(num_distractors-1)}\")\n",
    "\n",
    "# Val/Test set on \"Colors\" (spare 1 combination of shape + color)\n",
    "print(f\"Possible val/test comp. sets: {12 * num_share_looks * num_other_looks**(num_distractors-1)}\")\n",
    "\n",
    "# Single piece set on \"Colors\" (1 combination of shape + color)\n",
    "print(f\"Possible single comp. sets with {num_distractors} distractors: {1 * num_share_looks * num_other_looks**(num_distractors-1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible sets per uniq prop. with 2 distractors: 56448\n"
     ]
    }
   ],
   "source": [
    "print(f\"All possible sets per uniq prop. with {num_distractors} distractors: {96 * num_share_looks * num_other_looks**(num_distractors-1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pieces: 96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['F_purple.png', 'T_yellow.png', 'V_purple.png', 'I_blue.png', 'T_grey.png']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create all piece images first\n",
    "# There are only 96 possible combinations (for now)\n",
    "save_all_pieces = False\n",
    "data_images_dir = \"/data/compreg/sets/pieces\"\n",
    "if save_all_pieces:  \n",
    "    for shape_idx, shape in enumerate(shapes):\n",
    "        for color_idx, color in enumerate(colors):\n",
    "            save_piece_image(color, shape, data_images_dir)\n",
    "print(\"Pieces:\", len(os.listdir(data_images_dir)))\n",
    "os.listdir(data_images_dir)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create meta.json\n",
    "\n",
    "We map label, colors, shapes etc. to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color_to_idx': {'BLUE': 4, 'BROWN': 6, 'GREEN': 3, 'GREY': 7, 'ORANGE': 1, 'PURPLE': 5, 'RED': 0, 'YELLOW': 2}, 'idx_to_color': {'0': 'RED', '1': 'ORANGE', '2': 'YELLOW', '3': 'GREEN', '4': 'BLUE', '5': 'PURPLE', '6': 'BROWN', '7': 'GREY'}, 'idx_to_label': {'0': 'uniq_color', '1': 'uniq_shape'}, 'idx_to_shape': {'0': 'F', '1': 'I', '2': 'L', '3': 'N', '4': 'P', '5': 'T', '6': 'U', '7': 'V', '8': 'W', '9': 'X', '10': 'Y', '11': 'Z'}, 'label_to_idx': {'uniq_color': 0, 'uniq_shape': 1}, 'shape_to_idx': {'F': 0, 'I': 1, 'L': 2, 'N': 3, 'P': 4, 'T': 5, 'U': 6, 'V': 7, 'W': 8, 'X': 9, 'Y': 10, 'Z': 11}}\n"
     ]
    }
   ],
   "source": [
    "data_top_dir = \"/data/compreg/sets\"\n",
    "save_meta = False\n",
    "labels = [\"uniq_color\", \"uniq_shape\"]\n",
    "if save_meta:\n",
    "    metadata = {\n",
    "        \"shape_to_idx\": dict(),\n",
    "        \"idx_to_shape\": dict(),\n",
    "        \"color_to_idx\": dict(),\n",
    "        \"idx_to_color\": dict(),\n",
    "        \"label_to_idx\": dict(),\n",
    "        \"idx_to_label\": dict()\n",
    "    }\n",
    "    for prop_idx, prop in enumerate(shapes):\n",
    "        metadata[\"shape_to_idx\"][prop.name] = prop_idx\n",
    "        metadata[\"idx_to_shape\"][prop_idx] = prop.name\n",
    "        \n",
    "    for prop_idx, prop in enumerate(colors):\n",
    "        metadata[\"color_to_idx\"][prop.name] = prop_idx\n",
    "        metadata[\"idx_to_color\"][prop_idx] = prop.name\n",
    "        \n",
    "    for lbl_idx, label in enumerate(labels):\n",
    "        metadata[\"label_to_idx\"][label] = lbl_idx\n",
    "        metadata[\"idx_to_label\"][lbl_idx] = label\n",
    "        \n",
    "    with open(data_top_dir + \"/meta.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4, sort_keys=True)\n",
    "else:\n",
    "    with open(data_top_dir + \"/meta.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The annotation structure\n",
    "\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"id\": 0,\n",
    "    \"label\": 0, # 0: use target color, 1: use target shape to discriminate\n",
    "    \"target\": {\n",
    "        \"color\": 2,\n",
    "        \"shape\": 5,\n",
    "        \"image\": \"F_blue.png\"\n",
    "    },\n",
    "    \"distractors\": [{\n",
    "        \"color\": 1,\n",
    "        \"shape\": 5,\n",
    "        \"image\": \"F_red.png\"\n",
    "    },{\n",
    "        \"color\": 2,\n",
    "        \"shape\": 9,\n",
    "        \"image\": \"V_blue.png\"\n",
    "    }]\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "Note: We produce one sample for each order (although the model should get invariant towards this anyway),\n",
    "      but it seems easier to generate the dataset in this way (using for-loops) (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.pentomino import create_all_distractor_configs, PropertyNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes:  588\n"
     ]
    }
   ],
   "source": [
    "# Test first on \"single piece\" combs. (should be 588 ones)\n",
    "all_configs = create_all_distractor_configs(PieceConfig(Colors.BLUE, Shapes.T, RelPositions.CENTER), \n",
    "                                           unique_props={PropertyNames.COLOR},\n",
    "                                           num_distractors=2,\n",
    "                                           prop_values={\n",
    "                                               PropertyNames.COLOR: list(Colors),\n",
    "                                               PropertyNames.SHAPE: list(Shapes)\n",
    "                                           })\n",
    "print(\"Scenes: \", len(all_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create for each piece combinations of color and shape, but leave out a combination for val/test. \n",
    "The hold-out combinations are never seen during training. Still, every color and shape is seen.\n",
    "\n",
    "We produce the similiar amount of \"mention the color\" and \"mention the shape\" tasks for a combination. \n",
    "The meta-task is to find the unique property and extract that value from the target piece.\n",
    "\"\"\"\n",
    "counter = 0\n",
    "samples = {\n",
    "    \"train\": [],\n",
    "    \"val\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "selected_shapes = [Shapes.T]\n",
    "selected_colors = [Colors.BLUE]\n",
    "for shape_idx, shape in enumerate(selected_shapes):\n",
    "    for color_idx, color in enumerate(selected_colors):\n",
    "        filename = to_image_name(color, shape)\n",
    "        samples[split].append({\n",
    "            \"id\": counter,\n",
    "            \"color\": color.value,\n",
    "            \"shape\": shape.value,\n",
    "            \"image\": filename\n",
    "        })\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in samples:\n",
    "    with open(f\"/data/compreg/sets/{num_distractors}dits/{split}.json\", \"w\") as f:\n",
    "        json.dump(samples[split], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
